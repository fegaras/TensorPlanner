#!/bin/bash
#SBATCH -A uot166
#SBATCH --job-name="diablo"
#SBATCH --output="run.log"
#SBATCH --partition=compute
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=128
#SBATCH --mem=249208M
#SBATCH --export=ALL
#SBATCH --time=60    # time limit in minutes

nodes=$SLURM_NNODES
echo "Number of nodes = " $nodes

# Expanse node: 128 cores (126 available), 256 GB RAM
#   executor-cores = 12   (10 executors/node)
#   executor-memory = 24GB
#   num-executors = nodes*10-1
executors=$((nodes*10-1))
echo "Number of executors = " $executors

SPARK_OPTIONS="--driver-memory 24G --num-executors $executors --executor-cores 12 --executor-memory 24G --driver-java-options '-Xss512m' --supervise"

export HADOOP_CONF_DIR=$HOME/expansecluster

#module load openjdk hadoop spark
module load cpu/0.15.4 gcc/7.5.0 openjdk hadoop/3.2.2 spark

SW=/expanse/lustre/projects/uot166/fegaras

export DIABLO_HOME=$HOME/TensorPlanner
export SCALA_HOME=$SW/scala-2.12.3

PATH="$SCALA_HOME/bin:$PATH"

# location of data storage and scratch space on every worker (on local SSD)
scratch=/scratch/$USER/job_$SLURM_JOB_ID

myhadoop-configure.sh -s $scratch

# spark configuration generated by myhadoop
SPARK_ENV=$HADOOP_CONF_DIR/spark/spark-env.sh
echo "export TMP=$scratch/tmp" >> $SPARK_ENV
echo "export TMPDIR=$scratch/tmp" >> $SPARK_ENV
echo "export SPARK_LOCAL_DIRS=$scratch" >> $SPARK_ENV
source $SPARK_ENV

export SPARK_MASTER_HOST=$SPARK_MASTER_IP

# start HDFS
start-dfs.sh
# start Spark
myspark start

JARS=.
for I in `ls $SPARK_HOME/jars/*.jar -I *unsafe*`; do
    JARS=$JARS:$I
done

rm -rf classes
mkdir -p classes

scala_files="mult-diablo.scala"
for f in $scala_files; do
    echo compiling $f ...
    scalac -d classes -cp classes:${JARS}:${DIABLO_HOME}/lib/diablo.jar $f >/dev/null
done

jar cf test.jar -C classes .

spark-submit --jars ${DIABLO_HOME}/lib/diablo.jar --class Multiply --master $MASTER $SPARK_OPTIONS test.jar 1 10000 10

myspark stop
stop-dfs.sh
myhadoop-cleanup.sh
