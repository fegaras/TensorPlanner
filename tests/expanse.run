#!/bin/bash
#SBATCH -A uot166
#SBATCH --job-name="diablo"
#SBATCH --output="run.log"
#SBATCH --partition=compute
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=128
#SBATCH --mem=249208M
#SBATCH --export=ALL
#SBATCH --time=30    # time limit in minutes

module purge
module load slurm cpu/0.15.4 gcc/7.5.0 openjdk

SW=/expanse/lustre/projects/uot166/fegaras
DIABLO_HOME=/home/$USER/TensorPlanner
export SCALA_HOME=$SW/scala-2.12.3
export SPARK_HOME=$SW/spark-3.1.2-bin-hadoop3.2
# OPEN MPI was built using: --enable-mpi-threads --enable-mpi-java --with-slurm --without-ucx --without-hcol
export OPENMPI_HOME=$SW/openmpi

export PATH="$OPENMPI_HOME/bin:$SCALA_HOME/bin:$PATH"
export LD_LIBRARY_PATH="$OPENMPI_HOME/lib:$LD_LIBRARY_PATH"

JARS=classes:$DIABLO_HOME/lib/diablo.jar:$OPENMPI_HOME/lib/mpi.jar
for I in `ls $SPARK_HOME/jars/*.jar -I *unsafe*`; do
    JARS=$JARS:$I
done

rm -rf classes
mkdir -p classes

scala_files="mult.scala"
for f in $scala_files; do
    echo compiling $f ...
    scalac -d classes -cp $JARS $f >/dev/null
done

ulimit -l unlimited

# for each expanse node: 2 sockets, 1 executor per socket, 64 Java threads per executor
mpirun -N 2 --bind-to socket --mca btl_openib_allow_ib true \
       scala -J-Xms64g -J-Xmx64g -classpath classes:$DIABLO_HOME/lib/diablo.jar:$OPENMPI_HOME/lib/mpi.jar Multiply 1 10000 10
